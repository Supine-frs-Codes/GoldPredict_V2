#!/usr/bin/env python3
"""
é¢„æµ‹ç»“æœç›‘å¬å™¨
ç›‘å¬é»„é‡‘ä»·æ ¼é¢„æµ‹ç³»ç»Ÿçš„ç»“æœï¼Œå¹¶è‡ªåŠ¨å‘é€åˆ°å¾®ä¿¡ç¾¤
"""

import json
import time
import threading
import logging
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, List
import sqlite3
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from wechat_sender import WeChatSender

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PredictionFileHandler(FileSystemEventHandler):
    """é¢„æµ‹æ–‡ä»¶å˜åŒ–å¤„ç†å™¨"""
    
    def __init__(self, listener):
        self.listener = listener
        self.last_modified = {}
        
    def on_modified(self, event):
        """æ–‡ä»¶ä¿®æ”¹äº‹ä»¶"""
        if event.is_directory:
            return
            
        file_path = Path(event.src_path)
        
        # åªç›‘å¬é¢„æµ‹ç»“æœæ–‡ä»¶
        if file_path.suffix == '.json' and any(keyword in file_path.name.lower() 
                                              for keyword in ['prediction', 'latest']):
            # é˜²æ­¢é‡å¤è§¦å‘
            current_time = time.time()
            if file_path in self.last_modified:
                if current_time - self.last_modified[file_path] < 2:  # 2ç§’å†…ä¸é‡å¤å¤„ç†
                    return
            
            self.last_modified[file_path] = current_time
            
            logger.info(f"æ£€æµ‹åˆ°é¢„æµ‹æ–‡ä»¶æ›´æ–°: {file_path}")
            self.listener.handle_prediction_file_update(file_path)

class PredictionListener:
    """é¢„æµ‹ç»“æœç›‘å¬å™¨"""
    
    def __init__(self, config_file: str = "listener_config.json"):
        """
        åˆå§‹åŒ–ç›‘å¬å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = Path(config_file)
        self.config = self._load_config()
        self.wechat_sender = WeChatSender()
        self.is_running = False
        self.observer = None
        self.api_thread = None
        self.last_sent_predictions = {}  # è®°å½•æœ€åå‘é€çš„é¢„æµ‹ï¼Œé¿å…é‡å¤å‘é€
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "monitoring": {
                "file_paths": [
                    "results/realtime/latest_prediction.json",
                    "results/predictions/web_simple_prediction.json",
                    "results/predictions/improved_predictions.json"
                ],
                "api_endpoints": [
                    "http://localhost:5000/api/prediction/latest",
                    "http://localhost:5000/api/prediction/realtime",
                    "http://localhost:5000/api/prediction/ai_enhanced",
                    "http://localhost:5000/api/prediction/traditional",
                    "http://localhost:5000/api/prediction/auto_trading"
                ],
                "check_interval_seconds": 30,
                "enable_file_monitoring": True,
                "enable_api_monitoring": True
            },
            "filtering": {
                "min_time_between_sends": 300,  # 5åˆ†é’Ÿ
                "deduplicate_predictions": True,
                "max_predictions_per_hour": 12
            },
            "logging": {
                "log_file": "prediction_listener.log",
                "log_level": "INFO"
            }
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    return config
            except Exception as e:
                logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                return default_config
        else:
            self._save_config(default_config)
            return default_config
    
    def _save_config(self, config: Dict):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {self.config_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            db_path = Path("results/listener_history.db")
            db_path.parent.mkdir(parents=True, exist_ok=True)
            
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS sent_predictions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        prediction_hash TEXT NOT NULL,
                        source TEXT NOT NULL,
                        current_price REAL,
                        predicted_price REAL,
                        signal TEXT,
                        confidence REAL,
                        sent_groups TEXT,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                conn.commit()
                
            logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _get_prediction_hash(self, prediction_data: Dict) -> str:
        """ç”Ÿæˆé¢„æµ‹æ•°æ®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        try:
            # ä½¿ç”¨å…³é”®å­—æ®µç”Ÿæˆå“ˆå¸Œ
            key_fields = {
                'timestamp': prediction_data.get('timestamp', ''),
                'current_price': prediction_data.get('current_price', 0),
                'predicted_price': prediction_data.get('predicted_price', 0),
                'signal': prediction_data.get('signal', ''),
                'confidence': prediction_data.get('confidence', 0)
            }
            return str(hash(json.dumps(key_fields, sort_keys=True)))
        except Exception as e:
            logger.error(f"ç”Ÿæˆé¢„æµ‹å“ˆå¸Œå¤±è´¥: {e}")
            return str(time.time())
    
    def _should_send_prediction(self, prediction_data: Dict, source: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘é€é¢„æµ‹"""
        try:
            # ç”Ÿæˆé¢„æµ‹å“ˆå¸Œ
            pred_hash = self._get_prediction_hash(prediction_data)
            
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if self.config['filtering']['deduplicate_predictions']:
                db_path = Path("results/listener_history.db")
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute(
                        'SELECT COUNT(*) FROM sent_predictions WHERE prediction_hash = ?',
                        (pred_hash,)
                    )
                    if cursor.fetchone()[0] > 0:
                        logger.info(f"é¢„æµ‹å·²å‘é€è¿‡ï¼Œè·³è¿‡: {pred_hash}")
                        return False
            
            # æ£€æŸ¥æ—¶é—´é—´éš”
            min_interval = self.config['filtering']['min_time_between_sends']
            if source in self.last_sent_predictions:
                last_sent_time = self.last_sent_predictions[source]
                if time.time() - last_sent_time < min_interval:
                    logger.info(f"å‘é€é—´éš”å¤ªçŸ­ï¼Œè·³è¿‡: {source}")
                    return False
            
            # æ£€æŸ¥æ¯å°æ—¶å‘é€é™åˆ¶
            max_per_hour = self.config['filtering']['max_predictions_per_hour']
            if max_per_hour > 0:
                db_path = Path("results/listener_history.db")
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.cursor()
                    one_hour_ago = datetime.now() - timedelta(hours=1)
                    cursor.execute(
                        'SELECT COUNT(*) FROM sent_predictions WHERE created_at > ?',
                        (one_hour_ago.isoformat(),)
                    )
                    if cursor.fetchone()[0] >= max_per_hour:
                        logger.info(f"å·²è¾¾åˆ°æ¯å°æ—¶å‘é€é™åˆ¶: {max_per_hour}")
                        return False
            
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥å‘é€æ¡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def _record_sent_prediction(self, prediction_data: Dict, source: str, sent_groups: List[str]):
        """è®°å½•å·²å‘é€çš„é¢„æµ‹"""
        try:
            pred_hash = self._get_prediction_hash(prediction_data)
            
            db_path = Path("results/listener_history.db")
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO sent_predictions (
                        timestamp, prediction_hash, source, current_price, 
                        predicted_price, signal, confidence, sent_groups
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    prediction_data.get('timestamp', ''),
                    pred_hash,
                    source,
                    prediction_data.get('current_price', 0),
                    prediction_data.get('predicted_price', 0),
                    prediction_data.get('signal', ''),
                    prediction_data.get('confidence', 0),
                    json.dumps(sent_groups)
                ))
                conn.commit()
            
            # æ›´æ–°æœ€åå‘é€æ—¶é—´
            self.last_sent_predictions[source] = time.time()
            
        except Exception as e:
            logger.error(f"è®°å½•å‘é€å†å²å¤±è´¥: {e}")
    
    def handle_prediction_file_update(self, file_path: Path):
        """å¤„ç†é¢„æµ‹æ–‡ä»¶æ›´æ–°"""
        try:
            logger.info(f"å¤„ç†é¢„æµ‹æ–‡ä»¶: {file_path}")
            
            # è¯»å–é¢„æµ‹æ•°æ®
            with open(file_path, 'r', encoding='utf-8') as f:
                prediction_data = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€
            if not self._should_send_prediction(prediction_data, str(file_path)):
                return
            
            # å‘é€åˆ°å¾®ä¿¡ç¾¤
            result = self.wechat_sender.send_prediction_to_groups(prediction_data)
            
            if result['success']:
                logger.info(f"é¢„æµ‹ç»“æœå·²å‘é€åˆ°å¾®ä¿¡ç¾¤: {result['sent_groups']}")
                self._record_sent_prediction(prediction_data, str(file_path), result['sent_groups'])
            else:
                logger.error(f"å‘é€é¢„æµ‹ç»“æœå¤±è´¥: {result['errors']}")
                
        except Exception as e:
            logger.error(f"å¤„ç†é¢„æµ‹æ–‡ä»¶æ›´æ–°æ—¶å‡ºé”™: {e}")
    
    def handle_api_prediction(self, api_url: str, prediction_data: Dict):
        """å¤„ç†APIé¢„æµ‹æ•°æ®"""
        try:
            logger.info(f"å¤„ç†APIé¢„æµ‹: {api_url}")
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€
            if not self._should_send_prediction(prediction_data, api_url):
                return
            
            # å‘é€åˆ°å¾®ä¿¡ç¾¤
            result = self.wechat_sender.send_prediction_to_groups(prediction_data)
            
            if result['success']:
                logger.info(f"APIé¢„æµ‹ç»“æœå·²å‘é€åˆ°å¾®ä¿¡ç¾¤: {result['sent_groups']}")
                self._record_sent_prediction(prediction_data, api_url, result['sent_groups'])
            else:
                logger.error(f"å‘é€APIé¢„æµ‹ç»“æœå¤±è´¥: {result['errors']}")
                
        except Exception as e:
            logger.error(f"å¤„ç†APIé¢„æµ‹æ—¶å‡ºé”™: {e}")
    
    def _monitor_api_endpoints(self):
        """ç›‘æ§APIç«¯ç‚¹"""
        api_endpoints = self.config['monitoring']['api_endpoints']
        check_interval = self.config['monitoring']['check_interval_seconds']
        
        while self.is_running:
            try:
                for api_url in api_endpoints:
                    try:
                        response = requests.get(api_url, timeout=10)
                        if response.status_code == 200:
                            prediction_data = response.json()
                            
                            # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                            if prediction_data and 'current_price' in prediction_data:
                                self.handle_api_prediction(api_url, prediction_data)
                        else:
                            logger.warning(f"APIè¯·æ±‚å¤±è´¥: {api_url} - {response.status_code}")
                            
                    except requests.RequestException as e:
                        logger.warning(f"APIè¯·æ±‚å¼‚å¸¸: {api_url} - {e}")
                    except Exception as e:
                        logger.error(f"å¤„ç†APIå“åº”æ—¶å‡ºé”™: {api_url} - {e}")
                
                time.sleep(check_interval)
                
            except Exception as e:
                logger.error(f"APIç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                time.sleep(check_interval)
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.is_running:
            logger.warning("ç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return
        
        logger.info("å¯åŠ¨é¢„æµ‹ç»“æœç›‘æ§...")
        self.is_running = True
        
        # è¿æ¥å¾®ä¿¡
        if not self.wechat_sender.connect_wechat():
            logger.error("å¾®ä¿¡è¿æ¥å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨ç›‘æ§")
            self.is_running = False
            return False
        
        # å¯åŠ¨æ–‡ä»¶ç›‘æ§
        if self.config['monitoring']['enable_file_monitoring']:
            try:
                self.observer = Observer()
                handler = PredictionFileHandler(self)
                
                # ç›‘æ§é¢„æµ‹ç»“æœç›®å½•
                watch_dirs = set()
                for file_path in self.config['monitoring']['file_paths']:
                    watch_dir = Path(file_path).parent
                    if watch_dir.exists():
                        watch_dirs.add(str(watch_dir))
                
                for watch_dir in watch_dirs:
                    self.observer.schedule(handler, watch_dir, recursive=False)
                    logger.info(f"å¼€å§‹ç›‘æ§ç›®å½•: {watch_dir}")
                
                self.observer.start()
                logger.info("æ–‡ä»¶ç›‘æ§å·²å¯åŠ¨")
                
            except Exception as e:
                logger.error(f"å¯åŠ¨æ–‡ä»¶ç›‘æ§å¤±è´¥: {e}")
        
        # å¯åŠ¨APIç›‘æ§
        if self.config['monitoring']['enable_api_monitoring']:
            try:
                self.api_thread = threading.Thread(target=self._monitor_api_endpoints, daemon=True)
                self.api_thread.start()
                logger.info("APIç›‘æ§å·²å¯åŠ¨")
            except Exception as e:
                logger.error(f"å¯åŠ¨APIç›‘æ§å¤±è´¥: {e}")
        
        logger.info("é¢„æµ‹ç»“æœç›‘æ§å·²å¯åŠ¨")
        return True
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        if not self.is_running:
            logger.warning("ç›‘æ§æœªåœ¨è¿è¡Œ")
            return
        
        logger.info("åœæ­¢é¢„æµ‹ç»“æœç›‘æ§...")
        self.is_running = False
        
        # åœæ­¢æ–‡ä»¶ç›‘æ§
        if self.observer:
            self.observer.stop()
            self.observer.join()
            self.observer = None
            logger.info("æ–‡ä»¶ç›‘æ§å·²åœæ­¢")
        
        # APIç›‘æ§çº¿ç¨‹ä¼šè‡ªåŠ¨åœæ­¢ï¼ˆdaemonçº¿ç¨‹ï¼‰
        
        # æ–­å¼€å¾®ä¿¡è¿æ¥
        self.wechat_sender.disconnect_wechat()
        
        logger.info("é¢„æµ‹ç»“æœç›‘æ§å·²åœæ­¢")
    
    def get_status(self) -> Dict:
        """è·å–ç›‘æ§çŠ¶æ€"""
        return {
            'running': self.is_running,
            'wechat_connected': self.wechat_sender.is_connected,
            'file_monitoring': self.config['monitoring']['enable_file_monitoring'],
            'api_monitoring': self.config['monitoring']['enable_api_monitoring'],
            'monitored_files': self.config['monitoring']['file_paths'],
            'monitored_apis': self.config['monitoring']['api_endpoints'],
            'last_sent_predictions': dict(self.last_sent_predictions)
        }
    
    def get_send_history(self, limit: int = 50) -> List[Dict]:
        """è·å–å‘é€å†å²"""
        try:
            db_path = Path("results/listener_history.db")
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT * FROM sent_predictions 
                    ORDER BY created_at DESC 
                    LIMIT ?
                ''', (limit,))
                
                columns = [desc[0] for desc in cursor.description]
                rows = cursor.fetchall()
                
                return [dict(zip(columns, row)) for row in rows]
                
        except Exception as e:
            logger.error(f"è·å–å‘é€å†å²å¤±è´¥: {e}")
            return []


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    print("ğŸ¯ é¢„æµ‹ç»“æœç›‘å¬å™¨")
    print("=" * 50)
    
    listener = PredictionListener()
    
    try:
        # æ˜¾ç¤ºé…ç½®
        print("å½“å‰é…ç½®:")
        print(f"  ç›‘æ§æ–‡ä»¶: {listener.config['monitoring']['file_paths']}")
        print(f"  ç›‘æ§API: {listener.config['monitoring']['api_endpoints']}")
        print(f"  æ£€æŸ¥é—´éš”: {listener.config['monitoring']['check_interval_seconds']}ç§’")
        
        # å¯åŠ¨ç›‘æ§
        if listener.start_monitoring():
            print("\nâœ… ç›‘æ§å·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
            
            # ä¿æŒè¿è¡Œ
            while True:
                time.sleep(1)
        else:
            print("âŒ ç›‘æ§å¯åŠ¨å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\n\nåœæ­¢ç›‘æ§...")
        listener.stop_monitoring()
        print("ç›‘æ§å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        listener.stop_monitoring()


if __name__ == "__main__":
    main()
